
# Akash Network - GPU Working Group (wg) - Meeting #1

## Agenda

- GPU Proof of Concept updates from Artur
- What are the next steps for the GPU working group?


## Meeting Details

- Date: Tuesday, February 7, 2023
- Time: 11:00 AM PT (Pacific Time)
- [Recording](https://ulubxe7s3ulck6gkqezr25x66pfr5qmtphv2usi7aveb2yh5hn6q.arweave.net/ougbk_LdFiV4yoEzHXb-88sewZN566pJHwVIHWD9O30)
- [Transcript](#transcript)


## Participants

- Adam Bozanich
- Andrew Gnatyuk
- Andrey Arapov
- Anil Murty
- Artur Troian
- Boz Menzalji
- Cheng Wang
- Jigar Patel
- Joao Luna
- Max
- Pablo Estrada
- Rodrigo Rochin
- Santiago Paiva
- Scott Carruthers
- Tyler Wright
- Zach Horn



## Notes


### Updates

## **Transcript**

_This editable transcript was computer generated and might contain errors. People can also change the text after it was created._

Tyler Wright: Awesome. We're good to go Archer. Take it away.

Artur Troian: Alrighty. Right. Hi everyone. Let's that we have so many people. Um, so the topic today is to

Artur Troian:  Unreal. Probably some of the things related to the GPU. As well as what's our next step is going to be and probably some sort of roadmap this feature. Um, As you probably saw last week, as posted quite a few. Inside on the progress. And yes, we have

Artur Troian:  successful run of the GPU on their cars in sort of PSE mode. And we unfortunately, just because that work has started a little bit before we did. We introduce a special interest groups and groups. We took a bit all the approach and we did the PRC first. So now, we're gonna describe on what's actually supposed to be done and what studies we were going to roll it out. Um, this is pretty big like a change for us since we. I think, introduces, I believe this. It's like a huge huge feature and that touches quite a few parts of the Akash networks. They Rodrigo's notes and providers.

Artur Troian:  So I won't actually to download today, however, I won't be doing it. Of there was like a few issues inside of the PRC. However, I'm gonna try to unveil all the information and documentation and PRS as soon as they can. With the instructions on how to test it and probably about testing you would like to talk a little bit more in this call today. But to something's up, I will be posting a few documents inside World GPU in the community report. Are with all of the details. And the steps. So, the

Artur Troian:  What the rollout will be split into a few phrases. So number one will be the testing as we will need to test it on the as many Environments as possible. Once again, are details on that. We will be posting as soon as we. Summarize all those things. Then once the testing phase is over. We'll be playing in the networking rates, because the feature requires changes to deployment group, that thing cannot be rolled out without networking. Great on the mind, we'll be doing the network of great and once the network will create a successful, then we will be providing instructions for the providers on how to be in business gpu's. UM,

Artur Troian:  A thing that summarizes, it questions, comments. Yeah.

Anil Murty: Oh yeah, that's a pretty good summary. Just a couple of questions. What do we want to do about? Attributes. Do we want to worry about the attribute Spec? I, you know, a more formal spec or should we go with something less than formal? And then I guess?

Artur Troian:  Yeah.

Anil Murty: the other thing I was thinking about was just generally you know, talking about

Anil Murty:  the changes to STL and, and then some sort of beta test line of beta process to this, but yeah.

Artur Troian: Yeah, so yeah, great question about attributes. So what we will be doing for now is we're gonna reuse the same structure as for persistent storage. Just to speed things up. There. Um, and then we will be. Once we have the attributes design, completed and discuss this. And one working group, we will be just mike and migration and the migration is going to be the same as for persistent storage. But yeah. So for now, the structure will be as same as the persistent storage. I will be really that in the document as well.

Artur Troian:  Um, for the SDL. Yes, the SDL change is pretty simple. It's just gonna be one more entry in the resources. Specification is gonna be GPU entry. And how many gpu's tenant wants to request the GPU amount will be integer. So, there will not be fair and gpu's, as such for security reasons. So they tell us to pay for entire cost of the GPU as well as they're gonna be attributes. To allow user much specific, family vendor and so forth. So, those details on the attribute matching process, we're going to be doing a little bit later. so, once I release, Sort of.

00:05:00

Artur Troian:  Beta versions. So we can start testing because we can start testing without reviews and then we're gonna work on this structure of how we want to actually,

Artur Troian:  What kind of contributes and how we gonna name them for the GPU? Because that's our requires some like matching between the attributes on the provider notes. So we want to make them as similar as possible. Doesn't just gonna be easier for us to maintain. But yeah, so the, the execution phrases, the number one is actually done. So we can do, we can't deploy workload on a car and run, only the GPU, Of than the specification. Number two is the process and we Like probably gonna look priority from that until we have a beta done, the debt, as the has been defined. So once again, you will be all covering that in the document.

Artur Troian:  And after that, I'm going to think about the rollout face for the beta testing. So unfortunately, the beta testing is going to be quite challenging with the requires, some knowledge about how to

Artur Troian:  Change some things in the containing, the environment and so forth. So we will be having for me separate documentation for that. I don't need help called and Andrew to start it and then you will polish this documentation with this community. Just everyone understands it and can use it.

Artur Troian:  Once we have once, we have this sort of document ready, then we will be able to start by the testing for the. We'll think about the public testnet for that. We don't because we obviously cannot run it on the main app until the network.

Artur Troian: and, The private container registers support. Yes, of that. We haven't started with work yet. That's going to be probably delight a little bit. So once we are finalized all of the war and make sure that we cover all of the aspects of the GPU on Akash then we can I think about the product container register.

Anil Murty: Sounds good. Yeah, I think in fact we can even split that out of this because it's not like a blocker to getting GPU support out. I think the only thing I missed in this list was the network upgrade right after.

Artur Troian: Yeah, correct. We will be we will need to run network upgrades. Through your rolling on for the providers andâ€¦

Anil Murty: Okay.

Artur Troian: discuss today on this exchange. We might combine this network of great with a few other things just to simplify both. So we have at least as less than possible.

Anil Murty: Sounds good.

Anil Murty:  Any questions or thoughts from others? Based on what Artur said.

Adam Bozanich: Amazing. Arturthing so much. It's f****** awesome to see this.

Artur Troian: Right, there's no question from the community. I'm probably gonna have like, probably sort of public requests. Um, yeah, Max, I'll just give you an important second. So, We will be.

Artur Troian:  Yeah, we'll roll out some sort of maybe test. harder requirements that you would like to test the GPU on So right now the test has been done and development is going on Rtx 3000 series. but we would like to cover as many hardware options as possible, and it's not that the actual hardware that worries are but more probably drivers,

00:10:00

Artur Troian:  As different version of the operating system, like you want, for example, they're going to be different version of the Nvidia drivers that have implications on the container runtime settings and so forth. So that will be some sort of initials back for testing will be quite strict and we would like to follow it as close as possible. Actually, not the source possible just as this so, it's gonna see Allow us to focus on the actual issues that happen during testing phase instead of dealing with the different environments. But yeah later on we will be one list.

Artur Troian:  Okay, cool.

Artur Troian:  Yes, that's will be really GPU. Is only for now, the main reason is the kuda, so the coulda has support from the Nvidia. I know it was support actually like a mock-up from AMD, but they defecated it like years ago. So we won't be in the MD for now. However, what we roll out the media and make sure that works stable, then you'll be thinking on the other vendors result,

Joao Luna: Yeah, I was going to ask. What was the backend to to allow Gpu's on Kubernetes?

Artur Troian: I'm sorry, I didn't get the first part.

Joao Luna: The what's technology or the backend that that's allowing Gpu's to be used by Kubernetes.

Artur Troian:  Oh, there's nothing expensive is that? It's basically keep doing this device drivers and working along with the media driver as differentiated

Artur Troian:  oh yes. Sorry. And the media container runtime.

Joao Luna: Okay. Yeah, that's okay. That's it. Yeah, okay.

Joao Luna:  Thank you.

Artur Troian: Yeah. You know what? The graphics or no partitioning at all. The GPU gonna be used as a Use it or not, use it because I mean, we can partition it but we won't be doing that for security reasons. The GPU doesn't have memory protection as such at least the consumer grade. So, for now that will be only this way.

Artur Troian:  More questions. Being a good.

Artur Troian: Oh yeah, they have, let's say for one has two gpu's and the lease request to gpu's, they both gpues go to the assemblies and provider, won't be able to be it. that's, And the provider gonna have to set pricing. IT provider has different gpu's in the same mode. They're gonna have to have different pricing for each GPU, so that part is. So we're gonna have to extend with engine to provide the television on the

Artur Troian:  Build. So if you for some profiler uses custom beat script, they're gonna see all the information about the beat same as we do for persistence storage. So you can, you can have multiple presentation storage classes in the same provider and you can send different prices. So the same gonna be done for the GPS.

Artur Troian:  Yeah, yeah. Right.

Artur Troian: All right, so I think that's pretty much, Yeah. Now, go ahead

Joao Luna: Yes, our question. I was just wondering, so I can see GPU is being like a very requested resource. Will there will there be a mechanisms implemented so that like deployment? So for instance I can have an open deployment in that deployment would

00:15:00

Joao Luna: That like that GPU becomes readily available if Alice is closed and And closed in a sense.

Artur Troian: and,

Joao Luna: Diagrams out of funds.

Joao Luna:  So it will be right away available for others to two years.

Artur Troian:  Yeah, there's actually the question. So what answer is into parts and start from the end? So we have the first of all, we have withdrawal. Right? Where provider with response from this workout on regular basis and provider. Actually already does projection of van fans gonna end So, please runs out the funds. It will be closed regardless however, for gpu's the GPU workload are normally you know, fire rate that job to do some feed amount of work and then finish. So we will be having that for the GPU workloads. the Lee provider will close please assume as the GPU, so as soon as we're called exits,

Artur Troian:  we're gonna, we're gonna think about what the conditions for that is like, you know, the container exit, zero, for example, successful or error, And we will allow probably certain amount of starts. if the container exits, these non-zero error and that parameter will be configured through the SEL

Joao Luna: Okay, so we couldn't control it via an in-app in application error code or So here, I'm thinking more like on a let's say Akash native development where like my app would know which how to signal that.

Artur Troian: Thank you.

Joao Luna: That I'm not. Yeah I'm that I'm not like terminating in a zero. I'm terminating in like a specific error that will inform the provider.

Artur Troian:  Okay, yeah. So let me move this way. Normally when GPU you were closed finishes, right? the exit code is 0 so we can track that and that means the job is done and you have to if you want to repeat it you have to Run it one more time. So a great new lease. Probably if there is an error, we are going to allow tenants to Retry it a few times through the SDL parameter. Yeah, don't go ahead.

Adam Bozanich: And I'll just say like I think not sure. I think I kind of get these case and I just give a little bit of context on this stuff and maybe we could we could go back and forth a little more to make sure we're on the same page with respect your question. So the The way that deployments are deployed right now the way that they're configured andâ€¦

Joao Luna: and,

Adam Bozanich: Kubernetes, it's basically they can assumption that it's a service, right? So it's like if it fails of restart it, that was always like basically the MVP style of doing it with

Adam Bozanich: GPU workloads. I mean, we've always wanted to be able to like support batch workloads, but GPU workloads, like really like kind of require it because like, when it stops, we need to stop the lease. Okay. so, The like health check mechanism and that kind of stuff for service basically for services right now is they kind of hard coded to deal with services? And what we've been envisioning for quite a while now is to add annotations and the deployment that will say like basically restart conditions like whether or not, it's like a one-shot job or if it should restart on various conditions, etc, that kind of thing. So I think that's what our exercise talking about a little bit with respect to mix status serum.

Joao Luna: Okay. Then it drives me to to another question on that point before I move on.

Adam Bozanich: With respect.

Joao Luna: Who aren't we thinking on leveraging, the the jobs resource for that kind of stuff.

Adam Bozanich:  We? we could Yeah, we could it's possible, you know, all the Kubernetes stuff is like And yeah, we could use a job, you know, or we could, you know, kind of have our own thing. It depends. But we definitely want to have the flexibility to be able to control. That's A Just I kind of any job runner like you want to be able to have that and so you know we want to have that.

00:20:00

Adam Bozanich: That's that part.

Joao Luna: Because I see as I see it. Like so, sorry if I'm going a little bit off topicâ€¦

Adam Bozanich:  Go ahead, good.

Joao Luna: because the way I see it from, from my knowledge on GPU workloads, which is not that much. They usually are like ephemeral kind of cold sweat like a strict andâ€¦

Adam Bozanich:  Yeah, exactly.

Joao Luna: and yeah they have a limited time to execute. and then like, for me from my perspective, this makes kind of a big difference in how we price things andâ€¦

Adam Bozanich:  Yes.

Joao Luna: like, it's really, I think it stops kind of being a deployment, would be something like a Job in terms of a cash as well.

Adam Bozanich:  Yes.

Joao Luna: So it's a different abstraction from Kubernetes side but also from the, a car side might be a different kind of object with the different pricing mechanism. That would be to.

Adam Bozanich:  So let me let me clear, let me go through a few other days. I totally agree but let me go through a few other places where like kind of this model of it being a service based more clothes thing and doesn't really it's breaking down with with bench that work. That's and again this is something that we've wanted to do for batch style workloads for a while that they could it's it's really it comes to head with the GPU stuff. So we're talking about the pricing thing and there was a question I think about the there's an interest this issue with Big. Okay. So Issue is right now. So the way that the inventory works is that like you have some amount of CPU and some of storage or what have you and the bit engine actually reserves that amount as it. Creates a bit or have you. It was like. So if there's one CPU

Adam Bozanich:  And it's gonna create a bit, it reserves that CPU. So when you run it, if you win the lease and you run it, you know, you don't over bid essentially. Now that think like that whole thing works. Well, if you're assuming that workloads are gonna run for a long time, if they're like, if they're timed out and quite short, there's no reason why we can't queue up a bunch of workloads to run. So like they can happen in rapid fire progression. So there's some modifications that we can make to the way that inventory works. We do have like an over commit thing right now, but I don't think it's quite flexible enough for really, what we should be doing for scheduling GPU workloads. We should be able to have like basically, a queue of workloads that will run that opens up a lot of

Adam Bozanich: You know kind of sticky issues around timing and time bounding workloads and things but it is something that that we need to make at least more flexible and configurable then like,â€¦

Joao Luna: Mmm.

Adam Bozanich: all these things I'm talking about here. These are all gonna the aim of this, this big like, Provider Microservices project is just kind of open up all these kinds of things to make it easier to do. Like you can you can create your own, youâ€¦

Joao Luna:  Nothing.

Adam Bozanich: watchdog style thing that On to things like that. and so that's the, that's the bid into the bid engine and scheduling And retrying and how that stuff really the current model breaks down. So there's a paramount of work that needs to happen to, to make this thing be efficient for running GPU workloads.

Joao Luna: Here.

Adam Bozanich: I don't know if like the whole deployment model necessarily breaks down

Adam Bozanich:  or not, I haven't quite seen that, but I think that there does need to be like more information in it so that

Joao Luna: I mean, if we follow that queue like queue approach,â€¦

Adam Bozanich:  Yeah.

Joao Luna: it definitely changes kind of the pricing because it's not the moment that you make these because of these would represent that I have the intent of doing a workflow, but shouldn't be charged, I guess. And on that note,â€¦

Adam Bozanich:  Yeah.

Joao Luna: I would like to add just for documentation there.

Joao Luna: As this is like a scarce resource for for now, right? We could expect like a long queue If there's demand,â€¦

Adam Bozanich:  Yes.

Joao Luna: we should like take notes on how Google handles this from their like cloud computing servicesâ€¦

Artur Troian: If?

Joao Luna: which is similar to this.

Adam Bozanich: Interest.

Joao Luna: They have like Q. You basically tell them like I want to execute this and they'll cure it and whenever they are the quantum computer orâ€¦

Adam Bozanich:  Yes.

Joao Luna: whatever available date, you would execute and show the results. This is from like a scarce resource perspectiveâ€¦

Artur Troian: well, it Yeah,â€¦

Joao Luna: which gpu's might be at the beginning. At least like AI workloads or something.

Adam Bozanich:  Yeah.

00:25:00

Artur Troian: there's a few Unfortunately that a couple of issues was that the question number one is, there should be really good timing to know how much current workload, don't take time. To finish. Right before you commit, you have a queue. I was thinking of you about, you actually had some draft in there, but yeah, for now we in the first run, we won't have it for a number of reasons because that means really thorough testing. First of all, Uh, and the second of all, yeah, this is actually a really good call on the jobs for the Kubernetes. so, once again, the few things to consider number one is, Does GPU overload. Persist any data.

Artur Troian:  Before uploading it. If it does, right then it falls into under just regular deployment, stifle cell. So from that perspective, sorry from the perspective of you as a provider it doesn't really matter. We're on it as a job around as a deployment of Iran. There's a stable set so we can, we can select each of them depending on the conditions and requirements of the SDL. So, for example, if Isaiah has only GPU report in years, it needs just a couple A micro CPU unions and few RAM units. It doesn't need any points. It doesn't need persistent storage all and it needs to be run. Only ones. No matter the result. Yeah, that's probably a really good amount example of the job, but that can be a use case for let's say the

Artur Troian:  Deployment GPU you GPU record dots. A bunch of numbers stores that somewhere on the persistent storage. Then you need to somehow extract this numbers, right? So that's another use case of that but that's gonna be exactly what. So in terms of the pricing once again. So for now we want to have as much information as possible to the beat so, you can decide on

Artur Troian:  Pricing for now. So we're gonna treat the GPU just as the regular resource, let's say, as a persistent storage. So we want to make sure that the current model works. And then we're gonna move on with the features. Like, you know, the queues the bachelor quotes and so forth. Yeah. Go ahead.

Joao Luna: I just want, I wanted to touch on a point. You said earlier, So from format, you described would be the process to either decide. Like, it's, it's gonna be a Kubernetes job or like it's a, it's the deployment if it has our stateful set, if it has a persistent storage, I think that's the point where the deployment content kind of breaks off from the akash's perspective. Just wanted to know your thoughts and this

Artur Troian: No, I don't think so. So let's just deployment right for that and it's still the deployment. I would say You just deployment just has,â€¦

Joao Luna: Thank you.

Artur Troian: should I feed amount of time to leave pretty much and they can just condition to end. This deployment is

Artur Troian:  You know, possess exit that is some some code or whatever. It's the same. As, you know, these rocks out of fans and provider courses to provide a view closely, please just just, they're gonna be one more condition for provider to closely and that's pretty much it.

Adam Bozanich: Yeah. Like in terms of I think if you're thinking like oh there's a deployment object in Kubernetes and now we're going to maybe use the child objects that mean the deployment object on chain. It no longer is this the right model? And they're, they're kind of different. Contexts the Deployment Model on chains. It's just like saying what you wanted to deploy. the actual implementation of that on the like running, the workload is Is pretty much decoupled from that, like, even now we don't only, I don't even think we use, we don't even think we use a deployment object. so, like Yeah.

Artur Troian: We use both deployments that we said,â€¦

Artur Troian: depending on the persistology.

Adam Bozanich: Yeah. We staple set too. And so like, You know,â€¦

Joao Luna: My mind.

Adam Bozanich: those built-in things that are built in Kubernetes that Really? They they just pretty pretty simple. Like they're just kind of simple operators andâ€¦

Joao Luna: Really make. The.

Adam Bozanich: like you can pick and choose the one that makes sense for according to the settings of the workload, or we can kind of create our own but it just because we're using a different model and Kubernetes doesn't mean that like The chat.

00:30:00

Joao Luna: Yeah, I get that. It's just that the overall abstraction that they create. I think it makes sense on from having like deployments, like, on a crashes like a broader concept. We opened the door to weird like weird usages but I might not be a problem. We can always verify but I don't think like that social would be as maintainable as time. Progresses for instance, we are opening for like okay I want to limited time job that you just GPU and also, persist something. What happens to the persist stuff when the job 30 days?

Adam Bozanich: Yeah.

Joao Luna: I told him, It's like it runs for three seconds.

Artur Troian: well, it's going to be terminated It's going to be terminated for now is the same as the

Joao Luna: Something In the days. And how do we treat the data about it? because the user said he wants to persist

Adam Bozanich:  Okay. So there can be other workloads and the deployment like something that's serving up the the result and data can persist for that thing. But you know like Yeah I think that we need to definitely Write down all of the use cases that we have in target and basically, like, you know, make sure there's motivation for them and people are going to use them, you know, basically go through prior to prioritization step and And make sure that we can cover. What we decide, we want to cut it, the names of the things I think are like whatever like But especially on the Kubernetes side of things, very likely, just basically create our own operators. And that.

Adam Bozanich:  You know, that that being said, it's always fair to be like, Hey, it's the deployment model unchained, the right thing, or should we do something else? Like that's totally a fair game discussions that we should be having. We should be thinking about how to improve all the time. But yeah. So like in all like, this kind of batch mode of doing things that the gpu's kind of for not horses eyes, but like makes this actually have to confront now, really as being up a lot of these issues. And so, I think it's important, this is keep having the conversation about it. Definitely will probably spill over into

Adam Bozanich:  The deployments for, you know, CIGS the provider CIGS and things like that. It's a big project, we're underters doing it's like showing that it can be done in the current framework and we'll just have to continue shipping away. Making it more usable for people that have like, particular use cases with Gpu's. I'm looking forward to it. I think it's gonna be awesome project. but yeah, so please like I don't know where a good place like write these things down in us, maybe Maybe in you or Tyler can suggest where we can have these discussions.

Anil Murty: Yeah, I was just gonna jump in and talk about it. So well Luna, I think a lot of the things that you bring up are very valid points in. These are actually things that we have talked about when we were talking about this project internally before, we went to this World community model, you know, things like splitting of GPU instances. So, you know, provider is not completely blocked talking about. People being able to use private containers, which we don't support today, being able to have this queue concept so that the movement provider is released, it's available for being for the next ease, that comes around. All of these are things that make complete same. Okay. I think our goal right now is to try to get some sort of poc working so that we can, at least start to get a little bit of testing out there.

Anil Murty:  So I think authors focus has been on first getting a plane vanilla, Kubernetes instance working and then getting a akash provider working with Gpu's where the whole gpu's allocated. So, that's kind of the initial phase, but, you know, any other ideas, I think the best way to do it is to put them in the discord channel for this work group. So there's a WG - GPU discord channel. Please put any ideas and thoughts in there one of us you know, I can take the I can I can be the I can I can want it here to take all the ideas that get posted out there, curate them, and put them into a road map on the Github Repository for this work because so that's kind of my suggestion.

Artur Troian: Yeah exactly and just let one more thing. Five cents to the deployment discussion. Imagine like Right now, use the people need it as the website of that but imagine we just add one more model to the To that thing. Let's say some beyond manager right? And from talent perspective they to be honest. Don't ever Where the robot is running, still deployment. It can be run on the unmanager on the dedicated virtual machine, right? And it's still going to be deployment, but it's going not good.

00:35:00

Artur Troian:  But yes, I'm pointed out. There's a time. Comes you know, change the model or add new. Models to the deployment. Yeah, we we're gonna have me to consider it. And think about that.

Adam Bozanich: let's say, one last thing about all this too, is that It is born every prioritize, things and things are motivated. What do like we're building a cloud platform, which is like, It, it means so, so many different things. The different people like, Oh, what if you do this or this? And this and this, and it's like all super cool stuff. But what we actually have struggled with in the past is like

Adam Bozanich:  Yeah, we could do a billion different things and all these things. Sound awesome. But like What are people actually gonna use? Like, what's really like on day one like Do we have users for this particular thing? Like right or is this is this, Will This support, you know, are we adding functionality, that will eventually support some other quite big use cases like concrete, right? So like they even these things about like, Yeah, well it's there's persistent storage and we'll store it and they can send it somewhere. I think it's a really important is that like we find users that want to do these things and we understand their workflow and like we enable that workflow for them if there's enough support for it because otherwise We can add all kinds of stuff and we launch it and then the nobody uses it or there's no providers with it. Or What have you instance? It's something that

Adam Bozanich:  kind of made some technical Arizona in the past and just something, I just want to bring up so that it's in our mind that like we're talking about Gpu's and like there seems to be a lot of like it seems to be highly anticipated.

Adam Bozanich:  but, you know, like let's get like the concrete users and concrete providers and talk to them to see like you know, how we can help them rather than just like Wouldn't it be cool if kind of stuff? I mean, I love that stuff, but yeah. This one, this one, give that little spiel because it's it is this thing is so cool in our trust done, but we need to like stay focused on doing MVPs. That's all but I do also want to capture all these other ideas things that it brings up about, you know, pricing. I think it was really good point Luna about like, Well, if you have a lease you're sending in a queue, you shouldn't pay for that. I think that's something that no. If we go with the key route, we really have to address.

Tyler Wright: I think this is a good conversation to be having. Um, one thing I do want to bring up is meeting cadence. So with this working group, I know there were in the initial phases of POC and then there's going to be some discussion between potential meetings about various use cases. I just wanted to get with this group about does this time work, if? So, if not, when we can put some additional times in there, but how often does this working group to want to meet as we march towards Gpu's live on Akash?

Adam Bozanich: It works for me.

Tyler Wright: All right. Any thoughts about like bi-weekly versus like every two weeks as an initial cadence or artery of any thoughts on times between this meeting the next meeting. so that people have testing.

Artur Troian: I just Yeah, let me look. Yeah, let's do next. One on in two weeks.

Artur Troian:  I believe you're gonna have something but then the actually wait a second. Yeah, the time first will work, but then, I'm sure we can do on seven. Yeah, let's do on the 24th and then I'm gonna decide if you need when we can do next one.

Tyler Wright: Okay, terrific. So I'll put something in discord and I'll add something to the calendar that everyone should be added to about the next working group session. Then we can figure out a normal, cadence beyond a meeting on the week of the 21st.

Tyler Wright:  Does anyone have any other thoughts or questions that they bring up at this time? Go ahead and deal.

Anil Murty: Yeah, the last thing I threw out there for if you I guess two things are stored there for everyone on this card is one if you have ideas similar to what Luna had please drop them in the discord channel and I'll take the action to cure it all those into some kind of roadmap that put on to the work group Github page. And and then the second request I have is as people are participating in discord in, for example, the providers area or the minor mining area or whatever. If you see people that you think potentially are going to be providers of GPU capacity, whether it's somebody that's finding Aetherium, mining rate today or somebody from a data center. Please direct them towards this working group and because at some point once we have this poc and it's working, fairly okay. And you know, the initial data testers, what we want to do is start to expand into some of these bigger providers and see how things work out. Thanks.

00:40:00

Tyler Wright: Yes, great call on that. Um, cool. If there's nothing else. Then again, Neil Oh. Did someone have their hand up? Or was someone just raising roof? Okay, Pablo, do you hand up?

Pablo Estrada: no, I was just going to say that if there any Any type of like issues or or open things that that need to be like done in code. I'm happy to help. I'm just new in this group. So, whatever. If you have any, any places where I can go check out, I'm happy to help.

Tyler Wright: Amazing. Go ahead and

Anil Murty: Yeah, so I was gonna say, Hey, Pablo. So, I actually directed Pablo towards this call as well, so I can talk a little bit. So Arthur and Adam for your information. I think I shared this with you on slack as well. Pablo joined I think one of the channels a couple of days ago and said you know he's been a gopro, go developer for I think you said seven years right now. And so he would have to help out with anything that you know, we could use help with whether it's gpu's or other things that I go related, I pointed him to the node repository and the providers repository. But if there's anything specific that you can think of

Adam Bozanich: So many things, so many things. But yeah, and I think that It.

Adam Bozanich:  We need, we need to do a better job at like, kind of like making the whole project approachable so that like I mean I think that with, once you do that, you know, it's like there. There's just so much there for you to grab onto, but actually getting to that spot is, it's kind of difficult right now. But so I think that, you know, you know, just kind of like with anything just kind of kicking the tires, getting it up and running running through the dead environment, working with Artur to, like test test, his branches and things like that. And like You know, you know, you know this like we always say this to people that are onboarding with projects but like go through the documentation and improve it. As you do that, you'll get up to speed. You'll make it easier for other people, and then it's kind of like the up and running with the project.

Adam Bozanich:  Um, I know that Archer has this active branch of the of the gpu's, I don't? I don't know, Archer. If you're in a spot where you'd like other people to start spitting up a dev environment and testing it. Even without that, just run through the Dev environment on the vanilla branch.

Artur Troian: Yeah. Yes,â€¦

Pablo Estrada: Sounds good. Yeah, thanks guys.

Artur Troian: I, I would suggest to start first with the Unbunched, the vanilla branch on the pro on the provider report and just set up Dev environment because it's been pretty, to be honest to do. There are lots of things and, you know, the point of Contributing is as well as understand how to test it yourself. So once you get familiar with the wrong provided locally of the notes and transactions and you know how to debug it then yeah, sure. I mean, we'll be happy to Share of what's many issues as you can. That's actually the point of this group in terms of the sharing, the GPU workload. So, for now,

Artur Troian:  I don't think it makes sense for you to do it. Just for number of reasons, it has multiple cross-free for changes and it's gonna be really difficult to catch on this. We actually do in a little bit of application right now, we want to remove some part of the north located in the separate repo. So picking it up going to be a bit easier.

00:45:00

Artur Troian:  And in the future, when we implement such big changes, we're going to to go them, you know, repository repository instead of this time, it like touches quite a few reposits at the same time and they connected to each other in a creates a little bit of mass. So once we, I think after I release the beta testing, There's going to be more or less graduate for example contributions.

Artur Troian: Yeah. That's that's really cool as well. As you know, we've done a pretty the past terrible job on a documenting, a development environment. So I mean Adam and I we understand it pretty well. But for people that getting used that it's a little bit tricky and Along with the GPU, I'm working on releasing. The simplified guide on how to start the provider, as well as how to provision it locally. Because, for example, is the just just GPU, you cannot tell. I cannot test it for example, on my machine because I'm using Mac. So, I have to have separate SSH server and it needs to be configured properly and you need to build Docker image locally and then pass into this essentially. So it's like, it's a whole process.

Artur Troian:  And it's not well documented and we need to clean it up and make sure that on any Linux machine can be used without any issues. So yeah that's only once and once I do that we have it's gonna be very easier for example contributions to start performing. You know.

Joao Luna: On that note, I would like to add to things if it's useful. We can make a documentation on how we are approaching testing, our akash features. So how we me and my team are currently doing it, which might be useful. And the other note is on the process while you go to through the documentation and read about it, something that would be cool is if you can, I know things that concepts that you would like to be deeply or more deeply.

Joao Luna:  Explored things that you will find out, are missing and overall feedback on documentation, will be cool if you could take note, and then have a look on the SIG, dogs stuff and PRD that, I, I pushed it should be up like, I wanted to close it this week, by the end of this week. There's already a structure proposed, but it's open for change, obviously. And I, I'd love to have the community called there and and share their pains on that.

Artur Troian: yeah, I mean Yeah. Go ahead. Yeah definitely do that will be a computer test. The provider I mean it's gonna be definitely used for it. I think you talk a little bit different environments though. You more like a production. We have development environment and that's Drastically different from what is on the Production.

Tyler Wright: If?

Artur Troian: Just for example, we don't use hell for a number of reasons and development. And like, setting up the Kubernetes provider provisioning need and doing the settings. Once again, YouTube is being developed environment, lots of things needs to be done, completely different pilot. It's done on the production. But once again, do this documentation, please because there's going to be used by other providers andâ€¦

Joao Luna: If?

Artur Troian: they will want to test some features as well. So that's gonna be UN percent useful.

Joao Luna: Yeah. Yeah, sure. And yeah, I'll try to also make it as as broad as possible because I'm developing on an arm cluster.

Tyler Wright: and,

Joao Luna: So some things are quite different in terms of what I can use in terms of services. Yeah. I'll have that into consideration as well.

Tyler Wright: Terrific. All right. Um, I know we're coming up on time. Does anyone else have anything they want to talk about?

Tyler Wright:  Cool again there. I know there's another working group around client libraries later today. There's a SIG analytics happening on Thursday and there was another working group having tomorrow, actually around content moderation. So, plenty going on, really appreciate all you for coming to this working group session, I will schedule another one for the week of 21st. And again, please use a discord for conversation between meetings and obviously the github that Anil has linked at the top of the chat.

00:50:00

Tyler Wright: Cool. If there's nothing else. Then again, please everybody. Enjoy the rest of your day. Thank you. And we'll see you soon.

Artur Troian: And so wrong.

Pablo Estrada: Thanks guys. Take

Adam Bozanich: Okay.

Andrey Arapov: Cool. Thank

Meeting ended after 00:51:13 ðŸ‘‹


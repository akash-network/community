
# Akash Network - Providers Special Interest Group (SIG) - Meeting #5

## Agenda

- Update from Praetor team on GPU Testnet Support with demo. 
- Update from Praetor team on new provider helm based approach.
- GPU Testnet Update
- Open Discussion


## Meeting Details

- Date: Wednesday, May 24, 2023
- Time: 08:00 AM PT (Pacific Time)
- [Recording](https://if3z55gxv2gojopfrcixtyb2koadlpgx53jjgvdz5lj2ggziyujq.arweave.net/QXee9NeujOS55YiReeA6U4A1vNfu0pNUeerToxsoxRM)
- [Transcript](#transcript)

## Participants

- Andrey Arapov
- Anil Murty
- Boz Menzalji
- Deval Patel
- Eduardo Estevez
- Jigar Patel
- Kael Jabel Abbott
- Lowell Tarek Abbott Vidal
- Scott Carruthers
- Tyler Wright


## Notes

- There process has been transferred to helm process. This works for mainnet and testnet.
- Jigar talked about how they are bringing GPU provider setup into Testnet through their UI. There is a dropdown to setup a provider in mainnet or Testnet?
- Jigar gave a demo of setting up a GPU Provider for Testnet, because the process works for GPU providers and mainnet providers in the same way.
- The Praetor tools add Nvidia drivers to the provider at the beginning of the process.
- Praetor team is working on migration process for providers that are already set up via Praetor. 
- Most providers are in provider services. Providers are running different versions. Lease migration is the most important thing to think about. 
- Updates will be coming in next few hours for new provider setups, and over the next month for existing providers with active leases that have used Praetor's set up process.
- Deval asked if it multiple types of GPUs can be run in the same cluster?
- Anil mentioned that there is no support right now, but Artur is working on being able to support this feature. 
- When Artur is ready, Praetor team may need to tweak their work a little bit to support multiple types of chips in the same cluster. 
- Anil talked about GPU Testnet a bit. All Nvidia GPUs are eligble to come onto the GPU Testnet Akash.
- Scott mentioned that some cloud tools have drivers for Nvidia downloaded already. The feature that downloads Nvidia drivers is great from a user experience standpoint.
- Lowell asked about how to become a provider as well as how to support Akash setting up an indexer. 
- Anil and Ty shared the various strategies being shared for setting up an Akash Indexer.
- Any conversations related to sig-analytics should be had in the Discord. Lowell received some links, and will follow up in sig-analytics discord channel. 
- Anil asked what kind of CPUs or GPUs Lowell has access to? Lowell and his team have access to a whole bunch of options.  
- Deval asked if Overclock connected with Latitude team for GPU support.
- Praetor team managed a provider for Latitude last year, but Latitude closed their provider during the bear run, because the provider was not profitable. 
- Anil mentioned that part of the testnet is to match demand with supply, so that providers can see profitability. 
- With the new helm based approach, Insiders and others can support providers using any build. 


Demo:

- Jigar went through the new Praetor demo that leveraged the new helm setup. The demo was hosted locally for now, but will be moved to production soon.
- There are some bugs being fixed right now, but it should be pushed today. 
- The UI has not changed at all, but now they are focused on the back end. 
- Deval mentioned that there will be checks for Nvidia drivers to bypass some of the set up steps if it needs to happen. 
- There was an issue during the setup process that Praetor team fixed. 
- Deval and Jigar ran the demo a second time with success. 
- The provider that was setup via Praetor successfully received a bid via Cloudmos.




### Action Items

- Praetor team will share an update when code is in prod to be tested by community. 
- Praetor team continuing to work on helm based approach for existing praetor based providers. 
- Praetor team will stay in the loop about Artur changes for provider attributes which will enable


# **Transcript**

_This editable transcript was computer generated and might contain errors. People can also change the text after it was created._

Tyler Wright: Cool. It was Andrey. All right. Welcome everybody. To Sig-providers monthly meeting number five again, we have a pretty nice agenda for today. As previously mentioned, Pray Tour team out of last meeting was working on a number of big changes to the Prador Core product, as well, as again, since last meeting, while Pray Tour has been working on content. Moderation changes as outlined in the working group, they've been sidetracked to reprioritize being able to support the GPU testnet, which will be happening soon. I know a big part of the experience is setting being able to set up a provider a GPU provider. And so, the prayer team has done a lot of work to be able to support bringing on GPU providers onto the AKASH network. So, without further ado, I'll hand it over to the pay to our team to talk about some of the updates that have happened over the past couple of weeks / month.

Jigar Patel: Hey guys. Thank you so much for giving us the space. So I wanted to start with the like what we have completed over the past month. So our currently, our whole process is be on like transfer to the home, charts for new providers. So any new providers who wants to become a provider in in a minute or in a testnet available to use our new hand process, which obviously alliance with the current acrosion network process. So, kit, 3 years kid, as all of them will use our new updated hand process.

Jigar Patel:  Next, we are bringing GPU testnet for providers who wants to take part into our Testnet. Also will give us the a lot of leverage to bring GPU provider experience into Mainnet, right? So that's also is like, it's gonna be pushing today. After this demo will be preparing a couple of boxer we're fixing right now but after that we'll be posting that to you like basically our products and environment. So anybody wants to become whether In a testament, they can become a provider and bring on GPUs. So, without further ado, I'll start my demo. Let me share my screen.

Jigar Patel:  Let me know when you say it.

Tyler Wright: Yeah, I can see it.

Jigar Patel:  It's okay. Okay. Awesome. So our process mainly in terms of UI is not change greatly. We are focusing on the background processes, like how we're like creating order in the past. We used to have our like, custom process. Now, we change that to the handbag process. So any anyone wants to become a provider, will give in on the top down, so they can select minute or taste it before they connect their wallet, because we actually require to help them at least for a kid in their wallet because that is requirement for creating certain creating pro. I don't change

Jigar Patel:  That's why like we asked them to connect their wallet using like minute rotation. So what I'm gonna do, I'm gonna give you the demo for GPU testnet. So that will give us the port demo included because the whole process is based on the helm, also on GPUs using is in in the demo. So it's like a combined demo. So I'm going to see like a GPU testnet. And I'll try to I'll just make sure that I have the same. Okay. So once I connect, it's gonna ask me to add a GPU testnet to GPU chain to my calculator. If it's, if it's already included or added if you have used, let's say

Jigar Patel:  Our cloud most are tested, so you will not ask you again. So once you approve it, It's going to ask you obviously to sign once I sign it. It's gonna check if I'm already a provider on chain if I'm not and then I will process the same. I have one server with the GPU so I'm going to select that. I'm gonna copy.

00:05:00

Jigar Patel:  And then sorry. And then I'm gonna obviously like if you have a GPU then we can ask like Do you want to provide GPU or Not? Right. So if you know provide GPS, it's gonna say yes and then right now you're only supporting in videos as akash on network. So if you are on here other GPUs, we're not going to process that you probably like the progress, right? So again video Click Next.

Jigar Patel: Now, we're started our whole process now. This process takes a little bit more time because we are like preparing our server before. And then we like Go ahead and add like nvidia drivers and video like A lot of the process that happens before insurance will happen right now.

Deval Patel: What happened in the?

Jigar Patel: And once that's done, we'll see how the wallet imports and everything works.

Deval Patel: So in this, in this process we are assuming that everything. Everything is you know nothing is installed actually on this machine, right? So yeah, I like I talked to Scott and that was the general consensus that whenever somebody brings the, you know, machine, right. They don't have. And you know, and we get drivers or food installed if they have installed it, right? We are adding one more step there, right? We checks and our try to, you know, bypass that right. But right now, what we did is basically we took the server as it is right. There is nothing installed. It's a fresh copy of just who can do, right? And we are trying to install everything on it.

Jigar Patel: Yeah. And in a meantime like I'll just go through like the process so we're using help on k3s on, Kate has both. So after this update, like right now, I'm, I'm the demoing in in localhost, but we have some issues in Dashboard call, because we are just figuring out a couple of things. Once that's done, our target is to push today, so we can have all new process for new providers. So, every new providers will leverage and process from today, basically, and they can also be able to access gputation it feature as well. And if you have any question, please let me know because it's just gonna take like a couple of minutes.

Tyler Wright: Yet Jigar. I know this looks great and much appreciate this demo while we're waiting. I know that this is the Fed up for new providers that are that are being set up. Have you talked about maybe this is something for a future conversation, but have you talked about the migration of existing providers over to the new home process? And you walk through like maybe the strad your next steps potentially there.

Jigar Patel: Yeah, yeah. So we are already working on it. It's because a lot of the process are same when we are migrating, right? So those process are already updated. So now what's gonna happen is we we what we're gonna do next will bring this update pretty soon because the, the tweaking that we had to do was like Getting different kind of like versions. So, right now what happened is not everybody on the latest provider right now, like provider services. That's that's like biggest concern from our side which they were going to explain more.

00:10:00

Deval Patel: So what happens is that? Let's say right now, all our providers mostly are in, you know, provider service, which is, which is basically running a service as a service, right? If you want to move to the home, for existing providers, then we need to, you know, I know the cids and you know makes make few changes and stuff like So basically these migration right look how how that can be handled right is is more, I need to, you know, discussing detail with Scott, right? But yes, that is on the plan. Yes, we are working towards it, right? But for now, we are going to provide hand support. Like we are bringing hand support for the new providers. We will provide updates in coming weeks, definitely for you know, accessing providers to move to have

Tyler Wright: Perfect, thank you very much. So I'm just taking some notes in the background. Does anyone else have any other questions or waiting for this piece of the process to continue? Anything related to the new process or being able to our pay their team supporting GPU testing.

Tyler Wright:  Cool. No worries, if not.

Tyler Wright:  Does anyone else have any other topics that might? We might be able to discuss over the next like minute or a couple of minutes while this process is going on.

Deval Patel: I just want to retreat here. Another thing and, you know, bring on consensus, we are not supporting multiple GPUs on the same cluster. Correct. Different type of GPUs.

Anil Murty: Yeah. So, hey, there was Anil. So, yeah, actually, that is correct right now. So right now, we only support homogeneous clusters. So you have to have the same exact model running on the entire cluster and if you have a different model, you set up a different cluster but Arthur is actively working on supporting multiple models within a given cluster. So Technically, you know, under the hood, you can set up a cluster with multiple GPU models. Today, the challenge though, is that there is no way for the tenant to specify, which specific model they want their workload to be running on. So let's say you have a Nvidia rtx, 30 90, and then you have a test that we 100 both installed and set up at the same cluster.

Anil Murty:  The tenant has no way of specifying that they want, their specific workload to run on the v100 and not on the 390 because there's no support for being able to specify that as an attribute. So, what Author is doing is, he's working on supporting those attributes and he's hoping to have that done by. I think the end of this week or early next week. So that's where that stands. I hope that answers your question.

Deval Patel: Yes, it does. So once once it's ready, right? We might need to tweak our system a little bit, right? But that is a part of the support of testnet and we're happy to do that, okay? So keep us in the loop, right? And and we'll, we'll be happy to support that and we'll chat off more offline like in terms of how to support that.

Anil Murty: Sounds good. Yep. Perfect. That makes sense. I guess while we're waiting for this one quick question is the helm based approach that is only going to make a difference to people that are setting up a new project. So meaning People that have already gone through the process of setting up an existing provider.

Anil Murty:  The, the support for him is not going to really benefit those people anyway, right?

Deval Patel: Oh no, that's that. That was the, you know, previous question by Tyler and we are going to migrate them to help with support actually all of them.

Anil Murty:  Yeah, but guess what I meant was that they're not losing out on anything right now by not having access to the home base approach, because they've already set up a boy, right? And I think the main point, Yeah.

Deval Patel:  Important. So, so many major. Yeah. So the major thing high is happening is that like we have chronoplator for every day 8 a.m depending on the system time, it actually starts there system, right? You know, there was a hanging provider service thing happening and because of that, it some providers when not bleeding, right? So in the new home update from Arthur and and the Core team, the they have addressed this issue in terms of, you know, based on logs. They need they start the system, right? So that should be, that should solve the issue of, you know, providers multiple providers or more providers basically beating, right? Yeah.

00:15:00

Anil Murty: Icic got it. Okay. So that I guess,…

Deval Patel: So that yeah,…

Anil Murty: answer. It does impact.

Deval Patel: that would, that would be more helpful, you know, to all the providers in terms of, you know, where experiencing this kind of issues, right? Plus it would be easier for us to, you know, provide update or you know, Bring it up to date more frequently or more necessarily.

Anil Murty: Got it. So yeah. Okay. So it does impact existing providers as well and makes their the management.

Deval Patel: It does this.

Anil Murty: Are good enough. As far as installing these drivers in the toolkit, are you able to detect the specific model? I'm assuming you are right? When you when you go through the process here, Okay.

Deval Patel: Yes.

Jigar Patel: So yeah. On that note on I think on the last insider meeting you said that you we're gonna have GPU. I like a document that specified that. What kind of GPUs we're going to support, right? We kind of like we kind of incorporate that as well, right? So if we find that we are not supporting two series GPU from Nvidia, let's say to 20, 60, 20 70, right? Then we can, we can like, take that if if there is a way that we can find, they are running like 20, 60, 20 70, then we don't allow them to become more around you.

Anil Murty: Started. Um, yeah, I posted a link to the draft. Pull request with all the Incentivized testing plans. And that has a list of GPUs in there as well.

Anil Murty:  So yeah, take a look at that. If you get a chance, I'll update that today with some more feedback I got and then I'll also be linking to a spreadsheet that calls out the specific incentive amounts that people will get for setting up GPUs. And incentive is going to be basically based on the type of GPU. So if you're setting up like an h100, the incentive will be higher if you're setting up an RDX 30, 90, then the inside is going to be much lower. And then we'll have incentives for other things. But so, The hope is that, by doing this in my Promoting the testnet over the next week or so we'll get a lot of people hopefully interested in setting up providers and deploying and that'll basically get a lot more attraction to your application as well.

Tyler Wright: Real quick just for clarification sake Anil. I know in that document, it has the preferred kinds of Nvidia GPUs in the ones that are going to be incentivized. But for the sake of pretor, any Nvidia GPU is eligible to be brought up as a provider on the network.

Anil Murty: That's correct. So I would just limit it to the Ones. That

Anil Murty:  You have driver support for like basically don't don't just limit it to the people that are in the incentivized tested or the GPU models are inside. It always saying in that instant device testing document is These are the providers we really want and so we're going to pay you extra. We're going to pay you the incentive amount of the reward for setting these up but if somebody wants to set up some other GPU that is supported totally fine with just won't get the incentive. It's on.

Tyler Wright: Perfect, thank you.

Jigar Patel: So then like we will just not let them limit themselves, right? We can just like, go ahead and as long as they bring nvidia, we're okay.

Anil Murty: That's right now I don't know like if you go really old like a GPU that was that came out in the year 2000 or something. I don't know. We'll actually work like we have not tested all the models so that's a something we'll have to deal with as it happens.

00:20:00

Jigar Patel:  Yeah.

Anil Murty: Like if somebody tried setting up a really really old Lady GPU and it didn't work then we know Hey doesn't work and we can like add an exception to it or something.

Jigar Patel:  Correct. Yeah. Yeah, and yeah, so it just was talking to they were on like on this thing. It looks like like our AWS server is kind of like stock right now. So we're what we are doing is that we are taking this it will yes basically sport instances to stay tested out because it's like very quickly we can just taste it out and some of the time what happens is it in Insurance it cash talk. So, let me see if we can like

Deval Patel: You notes. It happened actually. This particular and it's always like that. I don't know why.

Deval Patel:  Okay. We can spin up another instance give us like a couple of minutes. I mean while we can work on like I mean we can move on to agenda off any other things and and give us you know Chance to spin up another instance and we can do that. Okay.

Tyler Wright: Yeah, no worries at all. Again with the while we're waiting for some of these changes to the demo? Does anybody have any specific questions related to providers? Whether it's in Mainnet or testnet that they want to talk about any questions comments, concerns?

Tyler Wright:  Seems a good. I know Andre. I don't want to put you on the spot. Are you here? You were here for a quick second. Um, yeah, cool.

Anil Murty: yeah, I think contradict

Tyler Wright:  Yeah, no worries. Again, this was the I'll go ahead, Scott.

Scott Carruthers: Yeah, just interesting conversation. So jigar, I believe earlier in the conversation, brought up that they're building in checks for the pre-existence of nvidia drivers. So one Deval and I were discussing this prior and the reason why that is a powerful as if you get into environments where you're building a provider and like Lambda Labs or Core Weaver, something like that these GPU called marketplaces already have and video drivers installed. So when we go to that process manually we just skip over the Nvidia GPU driver and their runtime installation in a manual process. But their building in process where they're kind of auto-checking to say that pre-existence of the

Scott Carruthers:  MBA toolkit in the Nvidia GPU drivers. So that that's a much appreciated, we'll be a powerful feature of kind of that auto detection. If the the drivers in the toolkit already exists, and if they do, then the Prater process will Not try to install the drivers when they're they're already in existence. So I just want to give a little more clarity on the work that's being done in those areas and like I said, this could be a powerful, very nice feature.

Tyler Wright: Okay, thank you, Scott. Go ahead Lowell.

Lowell Tarek Abbott Vidal: Oh yes. Yes. I would like to know more about the details of becoming a validator if that's possible. If you guys can send it over the email or in this message at the end, we we run around like 40 or 25 degree machines around three multiple regions. So yeah we would like to to see if we can put some of those providers in Aspero and become provider for a cash. And there's the second one is

Lowell Tarek Abbott Vidal:  I heard you guys have some needs regarding indexing and and it's regarding our tribal nodes with right. Now, we as part of our infra with round polygon x die and a lot of activity archival notes because what we do is we provide RPC calls, for, for pocket, which is at the centralization network, with daily process around, 100 to any million requests per day and we have machines and resources seen by and we will like to know More about how we can help you guys understand.

Tyler Wright: Absolutely, thank you very much. Um, I'll let some other folks chime in very quickly, but I know in terms of the analytics conversation, I know there's a couple of folks that are thinking about solutions, obviously, we would like all the potential solutions to be brought to the forefront and then let the community figure out what the best solution is for the sake of the community. If you want to continue that conversation on some ideas and again some further information around indexer and the archival node in the SIG Analytics channel, that would be great. There's also a discussion happening in Github where a group is talking about a potential solution and I know another group is working on developing, again, another solution for an index or so, anything related to the indexer and archival node should happen and sig analytics, but thank you for bringing it up. Now, does anyone else from on this call? Want to talk about that ever? So briefly,

00:25:00

Lowell Tarek Abbott Vidal: Thank you. I'll take a look.

Tyler Wright:  Perfect.

Anil Murty: If I can just jump in really quickly level. So, first off, thanks for bringing that up. As Title said, We're basically looking at three or four different options right now for an indexer. There is a proposal from the Cloud most team that exists inside the github discussions on our Github repository. If you don't know where that is, I can send you a link.

Anil Murty:  So that's one. And then there is a potential another proposal from another team that is likely to come through this week. For an indexer as well. There is a solution from a company called Sub Query that we're looking at. And be update another solution for a company called Lumia. So those four, the kind of options that you look at The main thing that we're interested in is. A index a solution that is open source. Ideally so that you know, in general are philosophy, is that the open source everything that we build? So we like to work with people that open source, their The products is with. and, and then of course it's got to have The ability to work with the Akash specific. Differences in the blockchain itself. So that's important as well.

Anil Murty:  so those are kind of the two main things if you have, I don't know like where your project is at what stage it is at if you have already built in indexer, if you have an indexer for someone osmos change, Or something like that. Posting any of that information into their SIG analytics channel would be useful, like any examples of other indexes that you might have would be useful to see. And and then if you want to, if if you're at a stage where you just getting started with your project for Akash and you plan to build an index, a specifically for our cash. Then, you're welcome to write a proposal and submit it to the GitHub discussions for the community to review and comment on.

Tyler Wright: I also.

Anil Murty: It's pretty good.

Tyler Wright: So no, I was just going to say just add to that quickly. And, you know, I just threw a message in there for Lowell that links to the SIG Analytics channel and discord as well as directly links to a message that Andrey put in there about steps on how to set up an archival mode.

Tyler Wright:  But yeah, much appreciate you bringing that up and sorry. Just like I couldn't hear the first part of the that you were mentioning. Were you talking about setting up, becoming getting more information on becoming a validator or getting more information on setting up a provider on the Akash network?

Tyler Wright:  The question for Lowell. Sorry, if you're on mute.

Lowell Tarek Abbott Vidal: Sorry, can you repeat?

Tyler Wright: Sorry, I, we talked in depth about the SIG analytics part, which I think was the second part of your question. I think, the first part you were asking, for more information on maybe becoming a validator or setting up a provider. I didn't understand that. So I'm just looking for clarity on the first part of your request.

Lowell Tarek Abbott Vidal: Yes, the two of Chinese first becoming a provider and I heard that there's a need also for running our Kyle notes.

Boz Menzalji: Yeah, let me just come in here real quick. Hey Lowell, I'm talking to you on discord as well. Just for context, everybody. I got to know, nude fleet through their delegation application and they provided a few different avenues where they can contribute. The first is, obviously validation. The second is running an archive knot and they're building an indexer as well or bear a chain, which is a massive project. And the third I'm just learning about it right now. Is they have provider capacity. So there are multiple avenues where we can work together Lowell. So I can follow up with you in discord and then share with you several paths where we can get you involved to process the delegation based on the contribution.

00:30:00

Tyler Wright: Go ahead and Neil.

Anil Murty: yeah, just kind of a follow-up to what was said, is So boss, you mentioned note Fleet is that the company that Lowell is part of or his company? Okay, got it. Okay. And then Lowell's, a quick question for you is since you mentioned, you're interested in becoming a provider if you could take a minute and talk about the kinds of computer sources, you have like, is it all Regular compute or do you have any GPUs as well that you can bring to the network?

Lowell Tarek Abbott Vidal: um, they are they are most of them. A big computers. Round 14 to 21 terabytes and BME. And from 48 to 64 CPUs amds, Also have here in my Are like two or three. Is. AMD thrift Wright. But since the, since since the ballroom finish, I didn't have any motivation to run. I was searching like other projects to Are said, maybe. Enter. Um, but I just keep everything disassembled, in the meantime, but most of our machines doesn't have

Lowell Tarek Abbott Vidal: Can configure GPUs on them and start also validating, or use it for a cash because some of the machines I'm using, they are on the localized, most of them because since they have a lot of CPUs, a lot of friends, I can use it for providing our services.

Anil Murty: Awesome. Yeah, so definitely take a look at the document that that posted on the Chat for Building a Cloud provider. That's the documentation for setting up a regular cpu-based provider. And if you're able to get GPUs attached to your existing CPU clusters, then we're going to have incentivized testnet starting in about two weeks from now. And we will be giving people extra rewards for setting up a GPU provider. So I have a draft document, the ratio. It's the first comment in the chat with the link there that talks about the process for how we're going to run this in device test it. You can see that one of the things in there is to set up a GPU provider. So if you're able to get, you know, GPUs attached to this, that is definitely something I'd increase you to participate in and set up a GPU provider because you'd get an extra incentive on top of all the

Anil Murty:  All the money that you would make from people deploying on to your provider?

Tyler Wright: Perfect, thank you. Well, you let us know if you need anything.

Jigar Patel: Oh sorry.

Deval Patel: Um, sorry.

Tyler Wright:  Okay.

Jigar Patel: Yeah, so we are ready to run over them again. Let's try again.

Jigar Patel:  Again, process is the same. Just gonna make sure that what it is the same. To put this net. To connect.

Jigar Patel: Also like this, this way, we will like the build our system because a lot of people gonna taste in in the testnet, right? So this will also give us the Give us the leverage to take all the feedbacks from all the users who's gonna test on it, right? And liking for process if they're like stock it somewhere. Like we basically get that feedback and like two more research on it as well.

00:35:00

Deval Patel: Just while we are waiting on this, you guys were talking about GPU, testnet. Incentivize, Did you guys talk to latitude guys? They, I think they they tag you on Twitter Anil. Correct.

Anil Murty: Yes. Yeah. I I Greg and I spoke with Guillermi. He's the guy who runs that company. And he is very interested in becoming a provider, our main interest in getting them is because they have ordered a bunch of h-100s that they're planning to set up at the time that we talked to him. Which was about three weeks ago, he had still not received his h100 yet. So he used to receive the restaurant 100 set up the clusters and then they'll be able to participate. So I'll hit him up again and see if he has them now, and we'll see if he can get them into their destinies with

Jigar Patel: Yeah, so with the laterity right? We basically we were last year, we were running there service as a provider into a carsh network. But they had to withdraw because obviously, because of the countdown and not profitability yet in the system, so they had to withdraw. But again, like I think that the GPU is best case scenario for them to be active on the, on the network as well.

Anil Murty: Oh, I see what's interesting. So, what was could you say that again? What was the reason for? Why they why you had to stop using latitude?

Jigar Patel: So basically, we were like, just we were what we can call it. We were like, handling their servers into the network, right? So we were not like paying them to bring those server, right? The problem was, he was When he came, he was like a bull run, right? So the price was very high Providence world. In fact looking at the successful profit, right? But what happened is after that we just like every like the whole market or turn down. Right? So what happened is he is like making more money if they can give those service into someone else, right? So he had to withdraw, right? Any explained me in a detail, right? Why here to do that in terms of like

Jigar Patel:  They do not they they're like they're the company where they have very like they have a lot of service but availability is not that high, like people are like using those two servers. So Like looks like if he has like more GPUs, then we can like leverage again.

Anil Murty: Make sense. Okay, got it. So he mainly he It wasn't for a technical reason, he decided to go up…

Jigar Patel:  No. Yeah.

Anil Murty: because he does not properly. Okay. Makes sense.

Deval Patel: He wants you think of the profitability at the point of time, right? And you know,…

Anil Murty:  Yep.

Deval Patel: some providers are not profitable, you know, all the time.

Anil Murty:  Yep. Got it. And yeah, that's a good point. And so what we're trying to do with this Testnet, is basically we're trying to match, We're trying to not just incentivize providers but also generate demand for the providers in the testnet. And the way we're doing that is by creating a

Anil Murty: um, you can call it like a competition or an exercise where We creating these tasks where we ask people to deploy AI models and we benchmark them and the goal is like because of because of those tasks people will you know, deploy their models and they'll run them for a while and they produce results. And what we'll get from that is not just demand for the providers but also testing out the Testnet and then producing marketing content similar to what you know, Lambda has done. For example, in showing how long it takes to run a given a model or run inference or benchmark, the GPUs using them. So that's kind of the hope that you're that you're shooting for with this test net. And so, hopefully the people that participate and become providers, it won't be a complete race for them.

Jigar Patel: Yeah, that's great actually and on a good note our process is running not like last time. So as you can see like we are all like all the process are using helm even like the engineering singers and everything. We are using help charts. Also running applying Nvidia runtime engine also. Like Think of this way, right? When you select NVIDIA, when you have any video, right? Or GPU? You selected. Yes. Then and then we'll be process this. Otherwise we just used to, We don't basically to Nvidia stuff. That's it, right? Hell, yes we are using On all the process. so I'm just going to use Preacher more, just copy

00:40:00

Jigar Patel:  So that's very fried, let me put the URL.

Jigar Patel:  Surprising the same. I'm going to put any attributes. And operator becoming border started.

Jigar Patel:  yeah, so using health cards now if you also make it easier for all the providers, all the new providers, Because we are like aligned now so they can get also support from inside as well. So next. Just have to do the changes which we already have done it. Next, so we are just fixing one bug here which doesn't let us our dashboard to show it. But once that's fixed, we'll push it to to the our production. So anybody can become a provider on on testing. So now what they were gonna see, usually it's just gonna deploy one. Honda element through Cloud Wars and we'll show you. I'm just gonna sit up presentation.

Deval Patel: You could first, let me show you guys.

Deval Patel:  The server actual server, right? So, let me know when you can see the screen.

Tyler Wright: Yep.

Tyler Wright: Maybe if you can zoom in just a little bit. So folks,

Deval Patel:  Yes. Yeah, I'm doing that right now. Are you able to say it now?

Tyler Wright: Yes.

Deval Patel: A little bit. Yeah. So as you can see, we just, you know,

Deval Patel:  We just created all this service, right? Like 108 seconds ago right to provider became right? We have this hostname operator as an order. Now, right before before that have process this provider was actually the service. Now we are using hub so you can see this as a board, right?

Deval Patel: You can see a band indexingles is also as a board, right? And and stuff like that, right? So everything everything looks good. I think we can check the logs as well.

Deval Patel:  Yeah, the logs are looking good, right? As you can see to allocable and total available, that is a like you know, CPU available CPU, available the memories there, right? And the storage. Right now, let's just do video, okay? So let me just let me stop the screen and present another screen.

Deval Patel: Let me know. Anything said, Yeah.

Tyler Wright: Yes.

Deval Patel:  Okay.

00:45:00

Deval Patel: Here. Yeah, so I think I think there's the same exact example GPUs deal we have in the in the documentation, right? And I'm just copying the copy paste in this, right? Help me try that. Fit. But

Deval Patel:  Insufficient capacity for resolution. Error.

Deval Patel:  That's why it's not like our provider is not bidding right now. Like, I got insufficient capacity for reservation error, right. I think it takes couple of like, you know, minutes for, you know, it to be available because some boards might be taking the resources as soon as you know become providers or the hanging, you know, orders. All that we noticed. Can anyone comment on this, or

Tyler Wright: Sorry Andrea.

Scott Carruthers: And so sorry. So

Scott Carruthers: Yeah, and all we could take a look at it together, so the the provider just came up and you're saying it's not bidding…

Deval Patel: Yeah, I'm sure I can I can show you the Yes,…

Scott Carruthers: because of insufficient resources. Yeah. After

Deval Patel: I see here, the big. I mean, big got time out and closed. Right? So now now if I, I able to see my screen or…

Scott Carruthers:  Yes. Yeah.

Deval Patel: no, Yeah. So see here, right?

Deval Patel:  Now, if I do, let's say a reservation. I mean a call, right? You might be able to see right? Just stopping it. And presenting it.

Andrey Arapov: Eternal Also query is 443 / status of the provider check, whether you can see the GPU and the amount of GPU available to see whether the cash provider can see digital resource.

Deval Patel:  Okay.

Deval Patel:  Let me try and upload one more time. Right. And see if this works.

Deval Patel: my provided build this time, actually, Okay. Do something, we need to type. I will notify Cloud Moss. There's some issue actually comes up multiple times where

Deval Patel:  In IP region or something.

Deval Patel:  Okay. Yeah, so as you can see here, this is the this is our provider, right? Like we, which we basically just oh no build, right? If I select this accepted. Who.

Deval Patel: And if I can go to Shell of this, Friendship commands this month.

00:50:00

Deval Patel:  See me? Yeah, that's Tesla for just, Right. So yeah, this is the like I'm in this concludes our demo, right? Like few things here and there we need to fine tune. But other than that, like I mean pretty much It's cracked on the.

Deval Patel:  Process, right? So it should be good to go by end of the day today,

Andrey Arapov: This is super cool though. And guys, jigar as well. Great job. Really looks awesome.

Jigar Patel: I thank you so much.

Deval Patel: Thank you. Questions concerns,…

Tyler Wright: Yeah.

Scott Carruthers: Yeah, yeah. Let's

Deval Patel: let us know.

Scott Carruthers: Criteria one down and rebuild it via Prater. So if you want to additional outside testing, just let me know and I can if I do that.

Deval Patel: Yeah, definitely. We were thinking first to, you know, put it in the in the, you know, our Dave environment, but then we thought, Let's not put it there and you know, directly put it into the our production. But we'll put that in that note that, you know, testnet is experimental, right? So you might find some bugs, right? But we are happy to address that and thank you the process down the line.

Scott Carruthers: Sounds great. Thanks.

Anil Murty: Very cool.

Tyler Wright: Okay. I know we're running up on time. I appreciate the prator team for walking through the demo and thank you for everybody that joined again. If anybody has an availability, there will be a six support by weekly happening directly after this. I know that the Pretor team is working closely with Scott Andre and others. If you can just continue to keep Sig-providers in the loop about changes and when people can access and start messing around with the pretor tool, that would be great Jigarh and Deval as well as perfect as well as I might bring this up as like, High level topic that we'll just discuss in the steering committee because again, I just want your work to be appreciated by the wider community. I know that we have a couple of demos happening tomorrow, so don't feel the need to demo but again, will shout you all out during the steering committee tomorrow, so just be prepared for that.

Tyler Wright: If there's any other last,…

Jigar Patel: Thank you so much.

Tyler Wright: Awesome. If there's any other last minute questions or thoughts about the presentation from the parade or team or anything sig-providers related? Please just throw those in the sig-providers discord channel. Again, if anybody has any time and desire, there will be a quick support by weekly happening just following this meeting. But again, much appreciate everybody for joining in a. Shout out to the prayer team for all the work that you're open doing. So, thank you all very much.

Anil Murty: Thanks Adam.

Tyler Wright: It's excellent. Everyone have a great rest of the day talk online and look out for some more information related to the GPU testnet coming soon.

Andrey Arapov: Thank you.

Eduardo Estevez: Thanks.

Tyler Wright: File.

Jigar Patel: You so much.

Deval Patel: Pretty much. Thank you guys.

Meeting ended after 01:08:51 👋


# Akash Network - Akash Network Provider Attributes Working Group-Meeting #2

## Agenda
- Welcome and Introduction
- Project Updates
- Demo of Benchmarking Tool
- High-Level Overview of Provider Auditing
- Next Steps and Planning

## Meeting Details
- Date: Wednesday, June 13, 2024
- Time: 10:00 AM PT (Pacific Time)
- [Recording](https://nergf5caumt4yjgrcif4bb6yxjrq6ftqaj52ge3l63ggj3qqlqaa.arweave.net/aSJi9ECjJ8wk0RILwIfYumMPFnACe6MTa_bMZO4QXAA)
- [Transcript](#transcript)

## Participants
- Anil Murty
- Benjamin B
- Deathless
- Deval Patel
- Jigar Patel
- Maxime Beauchamp
- oïclid
- Rodri R
- rUqeRT
- Scott Carruthers
- Tyler Wright

## Meeting Notes

**Introduction:**
- Tyler Wright welcomed everyone and provided background on the group’s formation.
- Noted issues with previous meeting timings and the availability of meeting notes and transcripts post-meeting.



**Demo of Benchmarking Tool:**
- Benjamin B provided an update and introduced the upcoming demo by Sebastian (rUqeRT).
- The benchmarking tool consists of four main parts:
  1. Indexer - Deploys to various providers.
  2. Benchmark - Runs the actual benchmarks.
  3. Database - Stores the data (using PostgreSQL).
  4. API - Gathers data from the database.
- Demo showcased the deployment process, running benchmarks, storing results, and accessing data via API.
- Example API call to fetch benchmark data for providers was demonstrated.

**High-Level Overview of Provider Auditing:**
- **Scott Carruthers:** Requested an overview of the provider auditing process and its integration with Cloudmos.
- **rUqeRT:** Explained the use of API for accessing benchmark data and potential for expansion.
- **Benjamin B:** Discussed plans to integrate benchmark results directly on the blockchain and signing benchmarks on-chain.

**Q&A Session:**
- **Anil Murty:** Asked about the benchmark comparison to a Raspberry Pi and its swappability.
  - **rUqeRT:** Confirmed it's possible to swap out the baseline comparison and provided rationale for using Raspberry Pi as a familiar baseline.
- **Deval Patel:** Inquired about the frequency of running benchmarks, handling hardware changes, and displaying benchmark results on provider status pages.
  - **Benjamin B:** Confirmed the capability to run benchmarks more frequently and discussed the potential for additional attributes.
- **Tyler Wright:** Clarified the goal of open-sourcing the auditing tools.
  - **Benjamin B:** Affirmed the plan to open source the tools and allow others to run them independently.
- **Deval Patel:** Suggested integrating the benchmarking tool as an optional part of core platform engineering for continuous data capture.
  - **Benjamin B:** Supported the idea for smaller benchmarks and uptime checks but highlighted challenges with more complex benchmarks like GPUs.

**Next Steps and Planning:**
- **Benjamin B:** Acknowledged the need for partnerships between auditors and providers for cost-effective benchmarking.
- **KYC Integration:**
  - Addressed the withdrawal of the KYC idea in favor of a decentralized trust system inspired by a hackathon submission.
  - Suggested multiple trusted entities could sign off on KYC, improving the trust system.
  - Discussed implementation strategies and the need for feedback from Scott regarding the best way to enable address-to-address trust sign-offs.
- **Console Integration:**
  - Mentioned the plan to either send back funds to the community pool or extend the deadline for integration.
  - Clarified the goal of integrating benchmarking results into Cloudmos and console for filtering and selection based on verified attributes and KYC status.
- **Uptime Indicator Clarification:**
  - Benjamin B clarified the current uptime indicator in the provider dashboards is based on the provider's ability to interact with the service rather than lease uptime.
- **Future Directions:**
  - Anil Murty suggested building a service that runs periodically to increase the number of variables available for users to select providers, considering both price and uptime history.
- **Next Session Planning:**
  - **Tyler Wright:** Asked about the timeline for the next demo and narrowing down the direction moving forward.
  - **Benjamin B:** Estimated a timeline of 14 to 20 days for the next demo.
  - **Tyler Wright:** Agreed to follow up offline to finalize the schedule for the next session.

**Closing Remarks:**
- Tyler Wright encouraged everyone to continue discussions in the working group for provider audit channel or the specific project tile.
- Benjamin B requested notes and transcript to be sent privately as an additional reference.
- Tyler Wright agreed to share the notes later in the day.

## Action Items
- **Benjamin B:** Share [links](https://github.com/luxas/benchmark) to the actual benchmark being used in the WG provider channel on Discord.
- **Tyler Wright:** Ensure meeting notes and transcript are posted in the repo for this working group and shared privately with Benjamin B.
- **rUqeRT:** Explore and document how to swap benchmark baselines for future flexibility.
- **All Members:** Review the shared benchmark links and provide feedback or suggestions on potential improvements or additional benchmarks to consider.
- **Benjamin B and Deval Patel:** Discuss the integration of benchmarking tools into the core platform engineering for continuous data capture and notification.

# **Transcript**

_This editable transcript was computer generated and might contain errors. People can also change the text after it was created._

Tyler Wright: All right, welcome everybody to the working group for provider audits. This group came out of a proposal that was put on Chain by piber Dev after conversations in Sig providers pi overdev and the pi 3 team puts together po a discussion that went on GitHub and then proposal that passed on chain for a automated auditing tool and then some other support work that was going into the cloud most indexer. There's been a couple of issues around timing for past meetings. But again, we're here to day to get update to all the work that has gone on since the inaugural meeting. I think which was in early April if anybody wants to track what's been going on again. There is a repo for this working group for provider Audits and you can see

Tyler Wright: After this meeting the notes and transcripts in the video will be available. Just like the first meeting and just continue to track moving forward. With that said again, there's a couple of members of the community and this has been shared wider. But I do want to kick it over to Benjamin to give us an update. I think since the last update that they provided in on the engineering project board, but Benjamin, I'll kick it over to you and you feel free to share screen and we'll just go from there.

Benjamin B: Thank you I don't have anything a concise yet. If you want me to make some notes off to this meeting I can write something there. But we have some few points. We want to share with you guys today. And the first one is actually with Sebastian who's going to present the demo of the benchmarking tool.

Benjamin B: Are you ready for that supposed to?

rUqeRT: Yeah. So person contacts into …

Benjamin B: also

rUqeRT: how the thing is structured. So it's comprised of four different parts like you got. An indexed as we call it. That's the one that actually deploys all of the to the different providers then when you have the actual Benchmark itself. Then we got the database to store everything in we decided on postgresql. and then just an API to that later gather all of the data from the database to let's see, where's the button for sharing screen?

rUqeRT: Yeah. I found it.

Tyler Wright: assuming that if you can see there's a ation, perfect

rUqeRT: So can everyone see this?

Benjamin B: Yes.

Tyler Wright: Yes.

rUqeRT: Yeah, so the main program that is deploying all of the benchmarks Brittany go. it doesn't And basic stuff to just set it up.

rUqeRT: later finds all of the things it needs. to the provider we have currently on the run it against the testnet. since we've just been developing and don't want to pay all the money that is involved in starting up and taking down deployments all the time. So it sets up the deployment then it waits for the benchmarks to run and then just the file from the image. And close the deployment then we push it over to the database. It takes a while to run this thing. So here we have an example all the logs. And don't worry about the credentials there. They're all just for the sandbox environment.

rUqeRT: So let's say it starts opinion. Yeah, so this is just the config needed to start it up.

Tyler Wright: Sebastian while you're doing that. There's a question in the chat. What image is this deploying the benchmarking Scripts?

rUqeRT: so we found a bench called Lucas Benchmark That we're using. can go into We made it sunlight modifications to it.

Tyler Wright: Go ahead Benjamin.

rUqeRT: So it's Benjamin pie better. Who's Has rear published the image. I could send you a link to the original benchmark.

00:05:00

Anil Murty: Okay, I think I drop the links to the actual Benchmark that you're using in the WG provider channel. That will be great.

rUqeRT: Yeah, could you fix that Benjamin? I'm doing this.

Benjamin B: Yeah to the district Channel.

Anil Murty: Yes, please.

Benjamin B: Sure.

rUqeRT: Yeah, so then that's all that waits for the Results come in and then this is the actual Benchmark that comes in. the summer part is The relative performance compared to a Raspberry Pi 1 model B. And this is just the actual raw data that it's performing against

rUqeRT: so then we just push this into the database we got. can

rUqeRT: show these are the different tables because to store the data. We got the actual Benchmark results. That's this first part. Yeah, overall the CPU RAM and real. this is then linked to these two which we call the bench specifications

rUqeRT: and then we just have providers that are unique records that all of these benchmarks are linked to and we also have a run log just to keep track of everything and make sure that things are running.

rUqeRT: Then on the API side once again, it's written in go and what you do is basically you run. This carol command.

rUqeRT: Where you ask for the different providers? And you get back all of the benchmarks for that provider?

rUqeRT: and that is basically

rUqeRT: that is how this thing works in a nutshell.

rUqeRT: Yeah, Benjamin.

Benjamin B: Yeah, I just want to start here. That's the benchmarker we have right now. Could easily be swapped out for anything else. This is just so we can show something if there's demand to

Benjamin B: to Benjamin's Market gpus to Benjamin smart networking anything else that could easily just be built. Basically. We just have to add more of the stls right now. We just made that single one, but we could just add more of them.

Benjamin B: Try other things. Is there any questions for this demo?

Anil Murty: Yeah. Yeah, this is great. Thank you for the demo. Could you dig a little bit deeper into the and I think you said this a little bit in class and I didn't catch it. But could you talk a little bit about the use you mentioned something about a Raspberry Pi and

rUqeRT: Yeah, just There's some part of them. And Mark data is compared to how much better it is than a Raspberry model 1B

rUqeRT: that is just something that is part of the benchmarket that we text.

Anil Murty: got it.

Anil Murty: Is that something that is? Swappable meaning can you replace who you're comparing against?

rUqeRT: That should be possible. Yeah. It's just that this gives you a nice kind of Baseline. So, because most people have at some point interactive with a Raspberry Pi Wright. Then you get that goes, Because oftentimes benchmark scores are quite abstract. So you don't really know what the Baseline is. just This is my machine and it's better than that machine or worse. but if you have a concrete point to measure it against gets a little bit easier to think about

rUqeRT: No, not yet. But Benjamin said Benchmark is quite easy to swap. Because it is just we change what image with deploy and we create some new models.

00:10:00

Tyler Wright: Go ahead Scott.

Scott Carruthers: so then if I don't want to distract from the current demo of benchmarking, so if We'd rather. Stick with that specific topic and then revisit this later. Let me know. I don't want to. be disruptive to this specific demo, but possibly just because it's been a period of time since we last met and there may be some people in the call that don't know these details at all. Is it possible also I wonder if this would be helpful for how everyone is conceptualizing this to provide a high level overview of the entire

Scott Carruthers: accounts of what provider auditing from your tools is going to look like and so in other words, I appreciate that. We're currently looking at benchmarking statistics and that it's ready to a database. Is this the entirety of the Focus right now and I also saw some updates that you're not currently looking at the integration with Cloud most. So I'm just wondering you go out and you do this benchmarking against different providers you write to a database and then how does that holistically fit in?

Scott Carruthers: and even how if we were going to include these benchmarks within provider attributes, how is that information getting into a providers attributes is the entire extent of the service at this point that we're just benchmarking writing it to a database and then it would be incumbent on other tools to bring that into it's

rUqeRT: You would probably use the API that we could expand in whatever way you'd like. it has one endpoint to get this but you could easily expand upon it do some processing and expose that as well. but just as a starting point,…

Scott Carruthers: okay.

rUqeRT: you can ask for the provider from this API and then you get the benchmarks for the API for the provider

Scott Carruthers: Okay, I see that has a hand raised as well. So might have some thoughts.

Benjamin B: Yeah, I have some more things to speak on this matter. I think this was actually a perfect time to break up from the demo on this and what has any more questions. You can leave the screen share of Sebastian. But otherwise, what's the last I mentioned about the API? It's true for console usage for other usage. Just having the API would probably be enough. But we still have some more things. And that we're going to talk about today. And we're still planning to release it. So that it's not just their Internet. It's also the blockchain directly the other assigned by fields. We will speak a little bit more on this circuit that we see. Actually, I can take that right now.

Benjamin B: So the idea is that when we have all the benchmarks and The Benchmark stls ready. And we just want to look at what is important for people to know is it up time? Is it CPU score? It's this and as soon as we have everything established here what people actually want to know. we can start signing people on chain for one address for everything that They want to know so if uptime being over 90% of this we can sign people that factor. If it's important to know if they have a CPU score I don't know over 500. We can sign people that as We don't have the demo for that today. but is that what you're asking?

Benjamin B: Yeah, so we would use the API from the other service later on to do all this and before I speak on some other points like How we wanted to do kyc and other things we still have planned and I want to let them all and Anil speak. So please go ahead and de.

00:15:00

Deval Patel: And so my question around is how frequently do you run this page practice and can we run more frequently than what we anticipate and I raised this question in discussions. sometimes what happens is that provider the hardware and change underneath changes right and that can change the Audited attributes in terms of CPUs and RAM and is there a way to and know that and how do we know those things on our side?

Deval Patel: As a dashboard or we have the provided status page what we want to show those things there as well. So yeah my questions around that as well as we do

Deval Patel: Right now in auditing the audit each attributes whatever the providers actually do are provide.

Benjamin B: Yeah, I will start 50 second question whether or not we can do more attributes than this and…

Deval Patel: So do you guys have that kind of capacity to do that?

Benjamin B: the answer is yes. We just have to include some more benchmarkers like we mentioned this one is really simple,…

Deval Patel: Let's say even the bandwidth they say what they have right like we manage and…

Benjamin B: but this one can be more advanced or…

Deval Patel: we sign that particular attributor as well.

Benjamin B: we can just create new ones. of how often we run it. I think this depends not of the software but rather how we make the business model later on we can definitely make sure that anyone can run it and it can be triggered in other way, but it would depend how would we make this self-sustainable? We'll do it and create a business model where people pay for Benjamin smarts when we get to network to sponsor it what we do our own benchmarks.

Benjamin B: so how much could we afford and that's a dependent north of that question so we could probably build so that regardless of who hosts the services. it's possible to choose how often you do it or if it fails if you want to retry And if you see any changes if you want to retry the benchmarks.

Benjamin B: It's this what you're asking or was there anything else as well?

Deval Patel: yeah, I think that's

Tyler Wright: Jigar, did you ever end up?

Benjamin B: awesome

Benjamin B: yeah, I think again this depends some providers could probably try to have some sort of limitations in their bidding Scripts if they don't want to be done our benchmarks. That's kind of up to them. if they don't pay down benchmarks, and maybe we don't have super expensive benchmarks. Some providers have a minimum amount to USD per month for them to accept it. maybe we won't be able to reach maybe those on the opposite side of the spectrum where They have super expensive a million akt per per block. We couldn't pay for those either. Of course. But other than that the plan is to a bunch work everyone. Yes, but again, it depends a little of

Benjamin B: at them go like how will the business model look like that kind of? makes a big difference was that's everything.

Tyler Wright: I had a quick question. I think Deval has a question after that. I understand the idea around the business model. And I think that's something we talked about during the steering committee and trying to make sure this is self-sustainable. But as I understand that the main component was an open source automated auditor that anybody could use to audit a provider. Is that still the plan? Because again I think that's the main product requirement. So I just want to make sure I understand the business component, but it's very much till the plan to open sources so that any other cool client Etc can also use the provider audit and benchmarking tools. Is that correct?

00:20:00

Benjamin B: This is correct. We want to make sure that anyone can run it themselves. If we can't host it ourselves. We're going to have everything open source for anyone to run. and the plan is that we were going to try to run it ourselves. But how long we can do that totally depends on other factors, but the main goal is the development of the open source tools. Yes. Please go ahead.

Deval Patel: So to say same thing, and that goes with the Tyler side, open source. Let's say if you open source, and we really, make this part of a core platform engineering thing then and we have four I mean pods running let's say inventory part is running to notify the inventory and stuff like that can we not make part of this as an optional tool there? They can deploy this part as in

Deval Patel: independent part and we basically capture the api's from that particular part and we showcase that to the providers are to the provided dashboard and provider status page? So, that way if we don't have to constantly ask for the beads rather than asking for bids like we can catch directly the data from the API.

Benjamin B: Yeah, I think that's a good idea. So basically we're skipping the deploying on a cost process and the providers can just willingly allocate some of their resources to us like to always other and this is a good idea it kind of Doesn't make sense. If you want to scale it, if you want to test the gpus, I'm sure that a lot of providers don't want to rent out one entire GPU or least that for free to the auditor indefinitely. but for a smaller benchmarks and for uptime checks and Things checks everything like that this talk to make sense. and then

Benjamin B: there's also the question of if you have this way of running it will provide us try to cheat it if they don't really know where it's coming from. and the last thing

Benjamin B: was one more thing therefore Yeah, if we want to update the benchmarks to do something else. It also might be hard to ultimately update that but the idea is good and it could work for some of the benchmarks for sure. please

Deval Patel: But I think what you can do with that part, is that whenever you want to run the Benchmark and frequency, You can grab the GPU at that point of time and then release it right and let's say all the gpus gets field right then we show the last status of the GPU what we had right stuff like that can be done and let's say even in your case, if you want to run a benchmark on a GPU and if the gpus are not available for that particular provider than what you're gonna do, right you will not be able to fetch that data at that point of time.

Benjamin B: This total makes sense. It could also be so that something like this would be a triggered as soon as some resources gets Freedom that you want to Benchmark and The Benchmark could run. So if you're renting all the gpus at once and then someone closes at least that could be the trigger to say. Yeah, we're ready to Benchmark now. I don't think we're going to and keep this in the current scope, but we would definitely be happy to help out and discuss how to further build results because right now our system is built on a completely different way. But we could probably figure out some way where we create the proper Integrations to our systems.

00:25:00

Benjamin B: Yeah, we did have some meetings in the past. I think one or two and this is a good thing to keep in mind for a future reference. Unfortunately, we can't really do anything about it now and I still think it's really valuable to do this via bidding. for making it cheaper. This will totally work. But then for this to work. You would have to need some Partnerships between the Auditors and the providers. If you're able to get that, it's not really certain whereas with bidding as long as the auditor wants to pay for the benchmarks or the provider wants to pay it or the networks. You can get it to work. Whereas the solution you're proposing. It will definitely work. But everyone would have to want to be involved. please go ahead and

Benjamin B: Also, thanks for that to know I can definitely cover that right now and let me have to go through my points really quickly and we can have all the questions later because this was already on the agenda. I just didn't make it clear enough. First of all, I want to quickly mention that for the benchmarker while we are going to continue developing it and making it for a moment Posh. We are going to make withdrawal for This Milestone the kyc idea.

Benjamin B: And that were going to work with. Different kyc providers but this is a very centralized way of doing it. If one kyc provider gets shot down. It really didn't work like all the development efforts will be done for in vain. and we had some internal discussion me and some other battle guards just a few days ago and we were talking about how to best to kyc not really kyc there. We were talking about a general trust system that we also want to help develop. Along with the kyc.

Benjamin B: we still are discussing what the best way of doing. This is Basically, what we wanted to do is start.

Benjamin B: Just like the services that we develop the open source tooling.

Benjamin B: And where everyone will be able to run we want everyone to be able to be able to kc hold on or what? It's on in a different way. basically We want to have different people and if you trust maybe overclock clubs, you can trust their Senators if you trust us for our science, you can trust us and we would prefer to keep everything here on Shane similar to how we are going to sign by the attributes. This will be done for kyc. Preferably and other questions like Imagine if overclock Labs were to sign everyone. At one of their employees have met at a convention.

00:30:00

Benjamin B: Maybe that's not a full proof way of trusting someone but it could definitely improve their trust if they're an Insider. Signed by overclock Labs. Maybe that's another thing that as you would trust. The list goes on. rotary sit important or ICU to cure handout I would prefer to keep the questions off through these points. If possible.

Benjamin B: We are not going to develop something like that, but we were actually inspired by one of the hackathons submissions where they implemented a way to pay with credit cards to get akt. We saw how they did their kyc and we're probably going to create our kosc system in a different way or in a similar way rather and also have some other things that you can sign by to create this cross system that anyone can get involved in. we're also trying to get some value like there's some other people right now too getting involved in this and as soon as we have the best way of the creating and implementing the system and we're going to work with a simple to beta test this

Benjamin B: the one thing that we were wondering when we had our discussion in the vanguard's chat is what could be the best way so that we can search of all of this. Or we're going to just create transactions with memos. We're going to create new transaction types or what would be the best I think this is a question maybe best. For Scott's to answer what we wanted to do here is we want any address to be able to sign other addresses? so that

Benjamin B: We want to make it clear. what one person thinks of another address? I don't trust this one. I've met this personally real life. This is an Insider. you can have any amount of questions and answers in this memory transaction. And we also want to find it very easily when picking out the provider or

Benjamin B: Or going to opposite way of which people do this person Go ahead Tyler.

Benjamin B: Thank you that the last thing on the agenda. Is the console integration? We were thinking of just not doing any work and sending back to the funds to the community pool. but we can definitely keep discussion open to continue working or continue with some sort of integration. We're going to make the API public. Either if you want to continue on that and maybe we can send the funds to you in some way or if you want us to continue. We would probably want to increase the deadline if that wouldn't be a problem with everyone else here.

Benjamin B: Yeah, but otherwise if nothing else like our original plan was just to send it back and not do anything, but we're open for ideas. Go ahead Scott.

Scott Carruthers: It is just to make sure that everyone is on the same page. What exactly would they integration with Cloud most look like or where would there be? Value I would assume that it would be in Claude most implementation of recommended attributes. But could make sure we're on this same page with what it integration with cloudmus would entail.

00:35:00

Benjamin B: And yes, just give me one second to open the proposal page.

Benjamin B: Yeah, so the idea I start we could include filtering for that for cloudmaster now console. So if you wanted to find the

Benjamin B: provider that has successfully shown that I'm capable being having this up time having these attributes verified or anything else you can just And quickly select what you need or if you need them to be from a certain region you can just filter that and to be able to only find those providers the assigned by the other API from us now. It's

Benjamin B: Yeah, and I lost the thing that we want to have here as well is the kyc thing. So if you only want to now we have the non audited providers. Another very important thing is having a versus non-ky seed provider. I think this should be enough for this answer, please go ahead Anil.

Anil Murty: Yeah, just going to the list of things contributions related benchmarking providers testing RPC know the tracking of time sort of these. It seems like what you've gotten so far and correct me if I'm wrong is. A portion of the benchmarking tool Is that correct? So track testing and no tracking of uptime. but

Benjamin B: this is correct we have not done in a contributions to the indexer and we don't Have the API or Benchmark to work on the RPC quite Jets? and we also haven't done the

Benjamin B: The filtering contribution on cloud nodes or console. and the rest while it's close, we actually have the last Point like half of that one right now what otherwise Pilates being worked on and It's quite close. We don't have it quite yet this meeting. No. I see some questions in the shortest world or some messages rather. And the kyc is not important for the benchmarking, but could be important. If you want to be able to trust their provider. It's a separate thing just like deathless basically if you want to run from a random Provider on the Internet or…

Anil Murty: Got it.

Benjamin B: if you want to run from a trusted company or person that kind of what we want to separate here.

Anil Murty: but it makes sense and then really quick Tyler one other question is so think just in my head right? I think what I was thinking and maybe other people jump in if they don't agree with this, but today we have a uptime indicator in the provided dashboards when somebody goes to deploy something. There's a similar uptime history just when you go to the details of Provider that available on both the pre-order dashboard as well as a cloud most dashboard. I think ultimately what will be cool to do is to build something that adds to that. So meaning today more than when people try to pick a provider the primary things. They try to decide please is based on the location the price and the uptime indicator integral. That's it. So I think ultimately we want to add something that increases the number of variables that people get to pick from and so this would have to be

Anil Murty: I think a service that runs periodically.

00:40:00

Anil Murty: Ideally, it would be something that gets deployed onto each provider. And it has to be small enough that it doesn't consume a whole lot of resources. There is the problem of how to be deal with this on the GPU side because it's an all or nothing outside of gpus, I think it's the way I was thinking about this. So to answer your question about what you should do next. I feel like this is early enough that there isn't that much that has been done. that it makes sense to potentially go in a different direction with this, but that's just kind of I thinking on this

Benjamin B: I think we're on the same page in kind of what we want to show on the console. I just want to make one thing clear here. Is that the uptime show unless something else has changed since I lost checked the uptime is not based of. How the leases are online or it's not based of that uptime. It's rather based of is the service running. They provider pulled or can the provider bid can they provider and do all of those things. Can you interact with the least shell All of those things is…

Anil Murty: That's correct.

Benjamin B: what is already being tracked and then something super small could just be tracked to get the actual uptime. I'm guessing.

Anil Murty: That's great.

Benjamin B: Yeah, and then for the other benchmarking things you mentioned. That makes sense. Yeah.

Benjamin B: Did you have anything else or should we leave it to Tyler?

Anil Murty: No, that is it. I think so. Overall. what I'm saying is I think if all you've gotten is one third of bullet number one, it makes sense for us to just revisit how we want to be doing. This periodic auditing, separate session and think about how you want to proceed from there.

Benjamin B: All right, I'll leave it to you Tyler.

Tyler Wright: Yeah, that was actually just my follow-up point because it seems like based upon these four General deliverables that are outlined. You're still fairly early in a number of these. So I was wondering to deval's point maybe obviously we're a little bit behind schedule. But do we have the ability to kind of direct how we're going to move forward from here to get these across the finish line so that they can be used by console and other members of the community. So it sounds like a near was talking about maybe doing another session where we can talk through some of these in a little bit more detail, but Benjamin, I just want to follow up with you about is that correct in terms of

Tyler Wright: these four deliverables and percentage done probably across the board is less than 25% for each of them. And so again, we have some time to shape the direction move forward and determine From a Time standpoint if you can get all these things done or the order of operations and getting those things done. That's just sounds like we saw some time to make some decisions as a group and kind of just narrow down where we're going from here. is that fair to say?

Benjamin B: No, I think. for most of this we're going to be able to finish them within the deadline, but then everything related to the

Benjamin B: contributions to console and the cloud loss. We're not quite sure if we're going to have much time to dedicate that it's cool. We could look into increasing the deadline or we can return the community funds for those things. But everything else should be able to be done within a month, hopefully.

Benjamin B: I'm open towards having more sessions to discussing more of these things. especially if you want to increase the deadline and do the Council integration in some other way But otherwise we haven't under control.

Tyler Wright: Got I'm reading your chat. And can you speak to this a little bit more if you can? I'm just trying to

00:45:00

Benjamin B: Yeah, I think especially for the council integration we can leave that. Just being a nullified but for the other things as I mentioned, we're developing it and should be done within the end of the month, even though we don't have the demos today to show everything. but those 100 hours For filtering and API usage of the clouds front end. We can definitely just return to the community pool.

Tyler Wright: Okay, perfect. Thank you for that clarification and in terms of I guess implementation of the automation of the auditor. I know you said you don't have a demo today. Do you know have a timeline when we can set up another session to have to demo that and then get feedback from the community and then again narrow down getting that to production as quickly as possible.

Benjamin B: I think the best thing here would be if we could shoot next time offline. So that we have the time to look at our schedules. Does that work for you guys?

Tyler Wright: Do you have a range of when you think that demo will be ready? Just so I can map out some time for us to have a loose schedule and then we can narrow it down from there. We're thinking seven days from having a demo or more 14 days.

Benjamin B: Selection what you think about roughly two weeks a few days before the deadline. It's

rUqeRT: I'd say maybe. 14 20 days

Benjamin B: at 14 to 20 days So the deadline is set the end of this month…

rUqeRT: Yeah, something like that maybe.

Benjamin B: if I'm not mistake 20 days. It's just a little bit into the next month. You start something that you guys are concerned with.

Tyler Wright: slightly concerned but I think whatever gets us to the point where again we can share it get some feedback and then Get this share with a larger Community would be ideal, so I understand that you all have other things. So it is what it is.

Benjamin B: Okay, so somewhere around there and 14 and 20 days and we should be able to meeting them.

Tyler Wright: Come here follow up with you offline over the next a week or…

Benjamin B: also

Tyler Wright: I know we have 10 minutes left. Is there any other questions that anybody has about where we are and some of the next steps?

Tyler Wright: All right. Benjamin I know you mentioned this at the top of the call, if you could drop in some notes when you get a chance on the product board in the issue that's created around this on the parking engineering board. That would be great. I'll make sure the notes transcript and recording are available as quickly as possible to share with other folks that maybe couldn't make it here today and then I will follow up with you over next seven to 14 days to get a better timeline of when we can get a demo so that folks on this call and in the community have enough time to plan and make sure that sound like a great next course of action.

Benjamin B: Yeah, that sounds like a good plan. Please also send me the notes in a private deal. So I'm able to have that as an additional reference…

Tyler Wright: Yes.

Benjamin B: if I forgot anything.

Tyler Wright: I'll do that later today when they're available. Thank you all for the demo.

Benjamin B: Thank you so much.

Tyler Wright: We'll follow up in the working group for provider audience Channel. If anybody has any questions again, feel free to reach out there or in the specific product that again, project tile that created around this that I'll drop in the chat again for folks. But again Benjamin Sebastian, Thank you all for all the questions and joining here today. I hope everyone has a great rest of the day.

00:50:00

Benjamin B: Thank everyone. Bye.

Scott Carruthers: Thanks guys.

Tyler Wright: thank

Jigar Patel: Thanks.

Rodri R: that

Deval Patel: Thank you guys.

Meeting ended after 00:50:16 👋

